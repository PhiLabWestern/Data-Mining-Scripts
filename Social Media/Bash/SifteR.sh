#!/bin/bash

#Select a range to be included in the processing...
startYear=$1
endYear=$2
#startMonth = $3
#endMonth = $4
echo $startYear
echo $endYear
echo "[" > [.add
echo "]" > ].add

mkdir ./parts/
mkdir ./Rparts/

#This is hard-coded to a directory of reddit comments.
#Change /mnt/f/Data/RedditComments/*/RC_ to DATA_PATH/<prefix if desired>
#There is likely a better way then eval ls to store this as temp too.
eval ls /mnt/f/Data/RedditSubmissions/RS_{$startYear..$endYear}* > temp

#Diagnostic if you want to see what is being found by the search.
#cat temp

while read p;
do
    #Extract file.
    echo "Extracting " $p
    t=$(basename $p | cut -f 1 -d '.')

    #This checks to see if the extraction has been done previously.
    if [ ! -f $t ] || [ ! -f ./parts/$t.txt.part.00 ];
    then
      dtrx $p
    else
      echo "Archive already locally extracted or previously split"
    fi

    #dtrx $p
    #Get unzipped filename in local directory.
    #dtrx didn't have an option to control the resulting directory location when I checked.

    #PreviouslySplit is used to indicate downstream whether to format the files or not.
    sed -n -e '/"subreddit":"londonontario"/p' $t > $t.txt
    #t=londonontariotemp.txt


    if [ ! -f ./parts/$t.txt.part.00 ];
    then
      #See below for split comments.
      split -C 8192m -d $t.txt ./parts/$t.txt.part.
      echo "Split successful"
      previouslySplit=FALSE
    else
      echo "Archive previously split. If split did not finish last run, exit script with ctrl-x-c"
      previouslySplit=TRUE
    fi
    echo $t.txt " has been extracted to JSON format."

    #Seperate into parts. 1gb size chosen for testing.
    # -C option is rather important - used to make sure there's a whole line ending each file. Script will fail with random end points.
    #split -C 8192m -d $t $t.part.

    #Select all parts generated by the above split command. A messy directory WILL mess up this command.
    filelist=$(find ./parts/$t.txt.part.*)

    #jsonliteFormat(){
      #local filename t should be one of the split files.
    #  local $f=$1
    for f in $filelist
    do
      echo "Cleaning " $f " to work with jsonlite::fromJSON"

      if [[ $(head -n 1 $f) != "[" ]];
      then
        #add , between all json objects to make an array
        sed -i 's/$/,/' $f
        #add array bounds
        #This is likely not well done and could be upgraded. Have to store the sed file again. Could use porting here maybe?
        cat \[.add $f ].add > $f.tmp
        # Delete the last occurence of , <- no efficient way to do this without re-reading the file!!!! annoying.
        sed -i 'x;${s/,$//;p;x;};1d' $f.tmp
        rm $f
        mv $f.tmp $f


      else
        echo "Archive previously split and presumably formatted. If split or the sed commands did not finish last run, exit script with ctrl-x-c"
      fi


      #echo "Running RScript on " $f
      #g=$(basename $f)
      #echo $g
      #if [ ! -f ./Rparts/$g.RData ];
      #then
      #  Rscript "/mnt/f/R Scripts/RedditProcess.R" $f
      #else
      #  echo "Existing .RData file found at ./Rparts/" $g.RData
      #fi
#    }
    done
    #mv ./parts/*.RData ./Rparts/

    #Parallelizing the 8gb file size ruins my PC.
    #parallelized loop, sort of? The & sends it to be a fork in the background.
    #for f in $filelist; do jsonliteFormat "$f" & done

    #Call the processing R script

    #Remove the unzipped file. Turned off for diagnostics.
    #rm $t
done < temp

#cleaning up files.
rm temp
rm \[.add
rm ].add
